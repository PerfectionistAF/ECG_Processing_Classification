{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2103529a-7c1e-447a-9d4d-73276a09b450",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "#pd.options.display.max_colwidth\n",
    "#pd.set_option(\"display.expand_frame_repr\", True)\n",
    "#pd.set_option('display.width', 1000)\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import wfdb\n",
    "import time\n",
    "import random\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "import sys\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "06ce5818-c9c8-4e0c-bd75-660c0b468a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install wfdb\n",
    "#!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "56f72e9d-2ad5-41b8-8712-0e9f3434da7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "##experiment with seed, run, channels(sinoatrial (SA) node, left feature lead, septal)\n",
    "##later experiment with channel averaging of physician diagnosis features of myocardial infarction\n",
    "##(septal average: v1, v2 ; left anterior average: v5, v6; left wrist: avl)\n",
    "seed_num = 39 #sys.argv[1]  ##required bash files\n",
    "#run_num = #sys.argv[2]\n",
    "channel_1 = 'v6'#sys.argv[3]\n",
    "channel_2 = 'vz'#sys.argv[4]\n",
    "channel_3 = 'ii'#sys.argv[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bd1acbe6-c2e0-4ba0-b8c8-c2e0365371bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./ptb-diagnostic-ecg-database-1.0.0/ptb-diagnostic-ecg-database-1.0.0/RECORDS') as fp:  \n",
    "    lines = fp.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2f4d607e-8cbd-44f9-8e17-e986a67b9f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##lines   ##read lines in dataset records.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f8138245-1855-4986-ae88-e4c4bea17ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "##divide into healthy and diseased .dat and .hea lists saved in files\n",
    "files_myocardial = []\n",
    "files_healthy = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "145971db-5e05-42ef-a887-dd9bf8d53f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in lines:\n",
    "    file_path = './ptb-diagnostic-ecg-database-1.0.0/ptb-diagnostic-ecg-database-1.0.0/' + file[:-1] + '.hea'\n",
    "    \n",
    "    ##read header to determine class ##focus on myocardial infarction\n",
    "    if 'Myocardial infarction' in open(file_path).read():\n",
    "        files_myocardial.append(file)\n",
    "        \n",
    "    if 'Healthy control' in open(file_path).read():\n",
    "        files_healthy.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6a62135b-911b-45d8-944c-68860212a0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#files_healthy  ##check with CONTROL\n",
    "#files_myocardial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d5671e03-660d-441e-ba4e-4380d2368557",
   "metadata": {},
   "outputs": [],
   "source": [
    "##shuffle data (cross-validation)\n",
    "np.random.seed(int(seed_num))\n",
    "np.random.shuffle(files_myocardial) \n",
    "np.random.shuffle(files_healthy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "48c8fd8d-5d58-4cc5-8419-022c1cd892e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "##split to train and test, 80% train, 20% test\n",
    "healthy_train = files_healthy[:int(0.8*len(files_healthy))]\n",
    "healthy_val = files_healthy[int(0.8*len(files_healthy)):]\n",
    "myocardial_train = files_myocardial[:int(0.8*len(files_myocardial))]\n",
    "myocardial_val = files_myocardial[int(0.8*len(files_myocardial)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "43d04e5d-7feb-4bf2-a735-6444010b3a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "##save names of train and val files\n",
    "h_train = pd.DataFrame(healthy_train)\n",
    "h_val = pd.DataFrame(healthy_val)\n",
    "m_train = pd.DataFrame(myocardial_train)\n",
    "m_val = pd.DataFrame(myocardial_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "102ea117-50a1-42af-942e-61fba09d6768",
   "metadata": {},
   "outputs": [],
   "source": [
    "h_train.to_csv(\"h_train_idx.csv\")\n",
    "m_train.to_csv(\"m_train_idx.csv\")\n",
    "h_val.to_csv(\"h_val_idx.csv\")\n",
    "m_val.to_csv(\"m_val_idx.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cc4f825a-703d-4959-8359-8b60181d4a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "##remove intersections\n",
    "def intersection(lst1, lst2): \n",
    "    return list(set(lst1) & set(lst2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d1c63aa6-e1ec-429b-827d-c1b9be79c033",
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_ids_healthy_train = []\n",
    "patient_ids_healthy_val = []\n",
    "patient_ids_myocardial_train = []\n",
    "patient_ids_myocardial_val = []\n",
    "##extract first 10 letters in file path string, which is the patient id\n",
    "for index in healthy_train:\n",
    "    patient_ids_healthy_train.append(index[0:10])\n",
    "for index in healthy_val:\n",
    "    patient_ids_healthy_val.append(index[0:10])\n",
    "for index in myocardial_train:\n",
    "    patient_ids_myocardial_train.append(index[0:10])\n",
    "for index in myocardial_val:\n",
    "    patient_ids_myocardial_val.append(index[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a82f70e7-4c45-4b0b-89d1-9bcd600253e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#type(patient_ids_myocardial_train)  ##list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "06dc89cf-0cd6-4d2d-82fc-62e217fdae55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(patient_ids_myocardial_train)) ##80% of total 148 patients is 118  \n",
    "#likely to have duplicates, so distribute intersection over train and validation sets\n",
    "#they can have common ecgs, used for checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "96c2dabd-4560-42ca-b140-a6a6fc1906cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(patient_ids_myocardial_val)) ##20% of total 148 patients is 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1a569adf-f848-4b29-a947-d4142c1d16ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#patient_ids_myocardial_val ##stable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "97c08128-a6d6-4d2b-96e7-3ba22cce0a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "intersection_myocardial = intersection(patient_ids_myocardial_train, patient_ids_myocardial_val)\n",
    "intersection_healthy = intersection(patient_ids_healthy_train, patient_ids_healthy_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "aaa14f6a-4a26-4a63-bcdb-85943db4bba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "##myocardial ##move half intersection to myocardial \n",
    "move_to_train = intersection_myocardial[:int(0.5*len(intersection_myocardial))]\n",
    "move_to_val = intersection_myocardial[int(0.5*len(intersection_myocardial)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "60ed47bd-beb4-4c7f-ac55-adaaf2e7b46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#move_to_train[0:5]  ##stable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b6ee2d21-7143-4279-8175-1308c5fd8a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for patient_id in move_to_train:\n",
    "    in_val = []\n",
    "    ##find and remove all files in val ecg readings by id\n",
    "    for file_ in myocardial_val:\n",
    "        if file_[:10] == patient_id:\n",
    "            in_val.append(file_)\n",
    "            myocardial_val.remove(file_)\n",
    "            \n",
    "    ##add to train\n",
    "    for file_ in in_val:\n",
    "        myocardial_train.append(file_)\n",
    "\n",
    "for patient_id in move_to_val:    \n",
    "    in_train = []\n",
    "    ##find and remove all files in train\n",
    "    for file_ in myocardial_train:\n",
    "        if file_[:10] == patient_id:\n",
    "            in_train.append(file_)\n",
    "            myocardial_train.remove(file_)\n",
    "            \n",
    "    ##add to val\n",
    "    for file_ in in_train:\n",
    "        myocardial_val.append(file_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b1a0b4a1-4b07-47de-a74f-de8ef4d1a38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##healthy\n",
    "move_to_train = intersection_healthy[:int(0.5*len(intersection_healthy))]\n",
    "move_to_val = intersection_healthy[int(0.5*len(intersection_healthy)):]\n",
    "#print(move_to_train[0:5]) ##stable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0f244c4a-5a55-4614-8b95-df4c111ea7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for patient_id in move_to_train:\n",
    "    in_val = []\n",
    "    ##find and remove all files in val ecg readings by id\n",
    "    for file_ in healthy_val:\n",
    "        if file_[:10] == patient_id:\n",
    "            in_val.append(file_)\n",
    "            healthy_val.remove(file_)\n",
    "            \n",
    "    ##add to train\n",
    "    for file_ in in_val:\n",
    "        healthy_train.append(file_)\n",
    "\n",
    "for patient_id in move_to_val:    \n",
    "    in_train = []\n",
    "    ##find and remove all files in train\n",
    "    for file_ in healthy_train:\n",
    "        if file_[:10] == patient_id:\n",
    "            in_train.append(file_)\n",
    "            healthy_train.remove(file_)\n",
    "            \n",
    "    ##add to val\n",
    "    for file_ in in_train:\n",
    "        healthy_val.append(file_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4984aba2-bfc2-4cab-8701-2a44efbc9707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(myocardial_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "137a9d3d-1fa7-4084-9de7-3e38db1cd1eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'patient240/s0468_re'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "healthy_train[0][:-1]  ##example file directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "be6d2e99-74d5-4147-8002-d6194b3261d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "##update index files\n",
    "h_train = pd.DataFrame(healthy_train)\n",
    "h_val = pd.DataFrame(healthy_val)\n",
    "m_train = pd.DataFrame(myocardial_train)\n",
    "m_val = pd.DataFrame(myocardial_val)\n",
    "h_train.to_csv(\"h_train_idx.csv\")\n",
    "m_train.to_csv(\"m_train_idx.csv\")\n",
    "h_val.to_csv(\"h_val_idx.csv\")\n",
    "m_val.to_csv(\"m_val_idx.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e337e579-ba75-44b8-851a-ca6b7ffbe674",
   "metadata": {},
   "outputs": [],
   "source": [
    "##all files extracted and cleaned successfully\n",
    "##now prepare a dataframe for the 3 channels\n",
    "##Index----II----V6----VZ\n",
    "data_healthy_train = []\n",
    "for file in healthy_train:\n",
    "    ##records for each\n",
    "    data_ii, _ = wfdb.rdsamp('./ptb-diagnostic-ecg-database-1.0.0/ptb-diagnostic-ecg-database-1.0.0/' + file[:-1], channel_names=[str(channel_1)])\n",
    "    data_v6, _ = wfdb.rdsamp('./ptb-diagnostic-ecg-database-1.0.0/ptb-diagnostic-ecg-database-1.0.0/' + file[:-1], channel_names=[str(channel_2)])\n",
    "    data_vz, _ = wfdb.rdsamp('./ptb-diagnostic-ecg-database-1.0.0/ptb-diagnostic-ecg-database-1.0.0/' + file[:-1], channel_names=[str(channel_3)])\n",
    "    data = [data_ii.flatten(), data_v6.flatten(), data_vz.flatten()]  ##flatten to input directly into keras model\n",
    "    data_healthy_train.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "171c970b-b99f-4780-8db0-0648ac5f3347",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-0.1245, -0.1275, -0.1305, ...,  0.188 ,  0.187 ,  0.1855]),\n",
       " array([ 0.458 ,  0.458 ,  0.457 , ..., -0.335 , -0.3325, -0.329 ]),\n",
       " array([-0.1025, -0.1   , -0.0925, ...,  0.062 ,  0.0695,  0.065 ])]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_healthy_train[0][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b231c499-66ed-4211-9a41-604b4dd7cbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "healthy_train_set = pd.DataFrame(data_healthy_train, columns=['ii', 'v6', 'vz'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f4b0d7f4-1b57-4761-87f4-4dfb65042591",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.1245, -0.1275, -0.1305, ...,  0.188 ,  0.187 ,  0.1855])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "healthy_train_set.at[0, 'ii'] ##input the first healthy patient in training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "cd724c82-87e8-4d54-b72d-f063e99ff60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "healthy_train_set.to_csv(\"healthy_train_signals.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7834d696-4abd-417f-b418-57d7c6fda2f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=61, step=1)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "healthy_train_set.index  ##test for iterating over rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4cd702eb-06a3-4831-95d9-37b901a01761",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_healthy_val = []\n",
    "for file in healthy_val:\n",
    "    ##records for each\n",
    "    data_ii, _ = wfdb.rdsamp('./ptb-diagnostic-ecg-database-1.0.0/ptb-diagnostic-ecg-database-1.0.0/' + file[:-1], channel_names=[str(channel_1)])\n",
    "    data_v6, _ = wfdb.rdsamp('./ptb-diagnostic-ecg-database-1.0.0/ptb-diagnostic-ecg-database-1.0.0/' + file[:-1], channel_names=[str(channel_2)])\n",
    "    data_vz, _ = wfdb.rdsamp('./ptb-diagnostic-ecg-database-1.0.0/ptb-diagnostic-ecg-database-1.0.0/' + file[:-1], channel_names=[str(channel_3)])\n",
    "    data = [data_ii.flatten(), data_v6.flatten(), data_vz.flatten()]  ##flatten to input directly into keras model\n",
    "    data_healthy_val.append(data)\n",
    "\n",
    "healthy_val_set = pd.DataFrame(data_healthy_train, columns=['ii', 'v6', 'vz'] )\n",
    "healthy_val_set.to_csv(\"healthy_val_signals.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "de0be2a4-a9dd-4189-86bc-e01a8f357c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_unhealthy_train = []\n",
    "for file in myocardial_train:\n",
    "    ##records for each\n",
    "    data_ii, _ = wfdb.rdsamp('./ptb-diagnostic-ecg-database-1.0.0/ptb-diagnostic-ecg-database-1.0.0/' + file[:-1], channel_names=[str(channel_1)])\n",
    "    data_v6, _ = wfdb.rdsamp('./ptb-diagnostic-ecg-database-1.0.0/ptb-diagnostic-ecg-database-1.0.0/' + file[:-1], channel_names=[str(channel_2)])\n",
    "    data_vz, _ = wfdb.rdsamp('./ptb-diagnostic-ecg-database-1.0.0/ptb-diagnostic-ecg-database-1.0.0/' + file[:-1], channel_names=[str(channel_3)])\n",
    "    data = [data_ii.flatten(), data_v6.flatten(), data_vz.flatten()]  ##flatten to input directly into keras model\n",
    "    data_unhealthy_train.append(data)\n",
    "\n",
    "data_unhealthy_val = []\n",
    "for file in myocardial_val:\n",
    "    ##records for each\n",
    "    data_ii, _ = wfdb.rdsamp('./ptb-diagnostic-ecg-database-1.0.0/ptb-diagnostic-ecg-database-1.0.0/' + file[:-1], channel_names=[str(channel_1)])\n",
    "    data_v6, _ = wfdb.rdsamp('./ptb-diagnostic-ecg-database-1.0.0/ptb-diagnostic-ecg-database-1.0.0/' + file[:-1], channel_names=[str(channel_2)])\n",
    "    data_vz, _ = wfdb.rdsamp('./ptb-diagnostic-ecg-database-1.0.0/ptb-diagnostic-ecg-database-1.0.0/' + file[:-1], channel_names=[str(channel_3)])\n",
    "    data = [data_ii.flatten(), data_v6.flatten(), data_vz.flatten()]  ##flatten to input directly into keras model\n",
    "    data_unhealthy_val.append(data)\n",
    "\n",
    "unhealthy_train_set = pd.DataFrame(data_unhealthy_train, columns=['ii', 'v6', 'vz'] )\n",
    "unhealthy_train_set.to_csv(\"mi_train_signals.csv\")\n",
    "unhealthy_val_set = pd.DataFrame(data_unhealthy_val, columns=['ii', 'v6', 'vz'] )\n",
    "unhealthy_val_set.to_csv(\"mi_val_signals.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f4a347bc-2ee8-418a-a78e-677783d19564",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########DEBUGGING: TEST GENERATION OF SLICES\n",
    "#unhealthy_indices = random.sample(sorted(np.arange(len(data_unhealthy_train))), k= 5)\n",
    "#print(unhealthy_indices)\n",
    "#unhealthy_batch = []\n",
    "#for i in unhealthy_indices:\n",
    "#    unhealthy_batch.append(data_unhealthy_train[i])\n",
    "\n",
    "#print(unhealthy_batch[0][0])\n",
    "#print(unhealthy_batch[0][1])\n",
    "#print(unhealthy_batch[0][2])\n",
    "##########DEBUGGING: TEST GENERATION OF SLICES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "489e7da8-8c39-4a03-acd8-4253e9480e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############COMPONENT ONE IN .PY FILES##############\n",
    "##normalize into batches, batch x and batch y (independent and dependent)\n",
    "##minmax norm\n",
    "window_size = 10000  ##from each ecg reading\n",
    "def get_batch(batch_size, split='train'):\n",
    "    ##random sampling of batches\n",
    "    ##divide batch number in half to improve speed of network\n",
    "    if split == 'train':\n",
    "        ##random samples from sorted per batch with size k = batch_size / 2\n",
    "        ##mimic shuffling\n",
    "        unhealthy_indices = random.sample(sorted(np.arange(len(data_unhealthy_train))), k=int(batch_size / 2))\n",
    "        healthy_indices = random.sample(sorted(np.arange(len(data_healthy_train))), k=int(batch_size / 2))\n",
    "        unhealthy_batch = []\n",
    "        healthy_batch = []\n",
    "        for i in unhealthy_indices:\n",
    "            unhealthy_batch.append(data_unhealthy_train[i])\n",
    "        for j in healthy_indices:\n",
    "            healthy_batch.append(data_healthy_train[j])\n",
    "    elif split == 'val': \n",
    "        unhealthy_indices = random.sample(sorted(np.arange(len(data_unhealthy_val))), k=int(batch_size / 2))\n",
    "        healthy_indices = random.sample(sorted(np.arange(len(data_healthy_val))), k=int(batch_size / 2))\n",
    "        unhealthy_batch = []\n",
    "        healthy_batch = []\n",
    "        for i in unhealthy_indices:\n",
    "            unhealthy_batch.append(data_unhealthy_val[i])\n",
    "        for j in healthy_indices:\n",
    "            healthy_batch.append(data_healthy_val[j])\n",
    "\n",
    "    \n",
    "    batch_x = []  ##batch of mixed healthy and unhealthy data\n",
    "    for sample in unhealthy_batch: ##if val or if train\n",
    "        start = random.choice(np.arange(len(sample[0]) - window_size))  ##randomly sample window from ecg \n",
    "        # normalize ecg values \n",
    "        normalized_1 = minmax_scale(sample[0][start:start+window_size])\n",
    "        normalized_2 = minmax_scale(sample[1][start:start+window_size])\n",
    "        normalized_3 = minmax_scale(sample[2][start:start+window_size])\n",
    "        normalized = np.array((normalized_1, normalized_2, normalized_3))\n",
    "        batch_x.append(normalized)\n",
    "        \n",
    "    for sample in healthy_batch:\n",
    "        start = random.choice(np.arange(len(sample[0]) - window_size))\n",
    "        # normalize\n",
    "        normalized_1 = minmax_scale(sample[0][start:start+window_size])\n",
    "        normalized_2 = minmax_scale(sample[1][start:start+window_size])\n",
    "        normalized_3 = minmax_scale(sample[2][start:start+window_size])\n",
    "        normalized = np.array((normalized_1, normalized_2, normalized_3))\n",
    "        batch_x.append(normalized)\n",
    "    \n",
    "    batch_y = [0.1 for _ in range(int(batch_size / 2))]\n",
    "    for _ in range(int(batch_size / 2)):\n",
    "        batch_y.append(0.9)\n",
    "        \n",
    "    indices = np.arange(len(batch_y))\n",
    "    np.random.shuffle(indices)\n",
    "    \n",
    "    batch_x = np.array(batch_x)\n",
    "    batch_y = np.array(batch_y)\n",
    "    \n",
    "    batch_x = batch_x[indices]\n",
    "    batch_y = batch_y[indices]\n",
    "    \n",
    "    batch_x = np.reshape(batch_x, (-1, 3, window_size))\n",
    "    batch_x = torch.from_numpy(batch_x)\n",
    "    batch_x = batch_x.float()#.cuda()\n",
    "    batch_x = batch_x.float()\n",
    "    \n",
    "    batch_y = np.reshape(batch_y, (-1, 1))\n",
    "    batch_y = torch.from_numpy(batch_y)  ##save tensors\n",
    "    batch_y = batch_y.float()#.cuda()\n",
    "    batch_y = batch_y.float()\n",
    "    \n",
    "    return batch_x, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a62c26e3-8a2f-4acd-8f41-656e9bf866e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "##constant batch size = 16  ##due to images ##or can be 10 \n",
    "##test given train\n",
    "##batch_x is the normalized windows of ecg channels in both healthy and unhealthy\n",
    "batch_size = 10\n",
    "batch_x, batch_y = get_batch(batch_size, split='train') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b4be6fb1-9adb-47b0-b1d1-41a03852650f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##save batch tensors in .txt for ready training and testing\n",
    "##assume 80 training batches and 20 testing batches ##each batch has a size of 5 or 8\n",
    "torch.save(batch_x, 'batch_x.pt')  ##encode in utf_8\n",
    "torch.save(batch_y, 'batch_y.pt')  ##encode in utf_8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2ab8f00b-1d8b-4e69-a16f-de4a681af03b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.1437, 0.1421, 0.1405,  ..., 0.2667, 0.2667, 0.2663],\n",
       "         [0.5625, 0.5632, 0.5619,  ..., 0.4991, 0.4997, 0.4991],\n",
       "         [0.0913, 0.0899, 0.0902,  ..., 0.3420, 0.3412, 0.3471]],\n",
       "\n",
       "        [[0.0657, 0.0600, 0.0600,  ..., 0.3689, 0.3668, 0.3673],\n",
       "         [0.3036, 0.2942, 0.2834,  ..., 0.2790, 0.2790, 0.2794],\n",
       "         [0.2583, 0.2592, 0.2610,  ..., 0.2350, 0.2278, 0.2305]],\n",
       "\n",
       "        [[0.2842, 0.2836, 0.2896,  ..., 0.2085, 0.2112, 0.2118],\n",
       "         [0.2325, 0.2298, 0.2312,  ..., 0.1868, 0.1734, 0.1694],\n",
       "         [0.2322, 0.2487, 0.2690,  ..., 0.3938, 0.4040, 0.4035]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.3166, 0.3161, 0.3161,  ..., 0.1739, 0.1723, 0.1675],\n",
       "         [0.1681, 0.1643, 0.1634,  ..., 0.1709, 0.1709, 0.1709],\n",
       "         [0.3528, 0.3549, 0.3555,  ..., 0.1548, 0.1575, 0.1585]],\n",
       "\n",
       "        [[0.0142, 0.0154, 0.0156,  ..., 0.6785, 0.6775, 0.6779],\n",
       "         [0.4780, 0.4752, 0.4757,  ..., 0.3006, 0.2987, 0.2992],\n",
       "         [0.7798, 0.7808, 0.7801,  ..., 0.0454, 0.0466, 0.0449]],\n",
       "\n",
       "        [[0.3058, 0.3061, 0.3061,  ..., 0.4223, 0.4223, 0.4229],\n",
       "         [0.3811, 0.3756, 0.3750,  ..., 0.2960, 0.2966, 0.2972],\n",
       "         [0.4817, 0.4807, 0.4853,  ..., 0.0073, 0.0073, 0.0073]]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##in model, import the get_batches from this module then start\n",
    "torch.load('batch_x.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a23e6783-3ad3-4e1b-8771-98f6fa7d1fc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9000],\n",
       "        [0.9000],\n",
       "        [0.1000],\n",
       "        [0.9000],\n",
       "        [0.1000],\n",
       "        [0.9000],\n",
       "        [0.1000],\n",
       "        [0.1000],\n",
       "        [0.1000],\n",
       "        [0.9000]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.load('batch_y.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b78a16eb-313c-499d-af4d-4a3963c7b6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy  ##disable truncations\n",
    "#numpy.set_printoptions(threshold=sys.maxsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "185efb9d-1ad1-4d7b-9ae7-ac47fc9503c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.1245, -0.1275, -0.1305, -0.134 , -0.134 , -0.1345, -0.1345,\n",
       "       -0.1345, -0.132 , -0.1295, -0.128 , -0.1225, -0.121 , -0.123 ,\n",
       "       -0.128 , -0.132 , -0.13  , -0.127 , -0.13  , -0.133 , -0.1305,\n",
       "       -0.1235, -0.1205, -0.121 , -0.121 , -0.1205, -0.1205, -0.122 ,\n",
       "       -0.123 , -0.1215, -0.1165, -0.1125, -0.1145, -0.117 , -0.1175,\n",
       "       -0.115 , -0.105 , -0.1   , -0.1095, -0.114 , -0.114 , -0.1145,\n",
       "       -0.1115, -0.104 , -0.103 , -0.1075, -0.1105, -0.114 , -0.1135,\n",
       "       -0.1115, -0.108 , -0.107 , -0.114 ])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_healthy_train[0][0][0:53]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "3e6d3224-e38c-453e-9bb1-13818193ffe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.458 , 0.458 , 0.457 , 0.4555, 0.453 , 0.45  , 0.449 , 0.45  ,\n",
       "       0.448 , 0.4455, 0.4465, 0.4505, 0.4515, 0.4535, 0.4585, 0.4605,\n",
       "       0.4655, 0.4715, 0.4715, 0.4715, 0.4765, 0.4795, 0.4795, 0.482 ,\n",
       "       0.487 , 0.4875, 0.485 , 0.483 , 0.4805, 0.479 , 0.4795, 0.482 ,\n",
       "       0.483 , 0.4795, 0.4785, 0.476 , 0.472 , 0.473 , 0.4785, 0.484 ,\n",
       "       0.4825, 0.4785, 0.4725, 0.4625, 0.459 , 0.457 , 0.4535, 0.4565,\n",
       "       0.4605, 0.465 , 0.4725, 0.477 , 0.481 ])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_healthy_train[0][1][0:53]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a0fcae5c-b2e9-48d5-a1f5-4ee459e831a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.1025, -0.1   , -0.0925, -0.0885, -0.0905, -0.0905, -0.0895,\n",
       "       -0.085 , -0.08  , -0.0825, -0.0835, -0.067 , -0.064 , -0.0665,\n",
       "       -0.064 , -0.0685, -0.0695, -0.082 , -0.0865, -0.085 , -0.089 ,\n",
       "       -0.0855, -0.087 , -0.091 , -0.091 , -0.092 , -0.09  , -0.0805,\n",
       "       -0.0745, -0.075 , -0.0705, -0.07  , -0.081 , -0.086 , -0.0935,\n",
       "       -0.105 , -0.0935, -0.08  , -0.0865, -0.0795, -0.073 , -0.0835,\n",
       "       -0.0895, -0.0915, -0.0885, -0.0925, -0.1015, -0.105 , -0.105 ,\n",
       "       -0.1005, -0.1035, -0.109 , -0.113 ])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_healthy_train[0][2][0:53]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c19eecd-8bc0-4fcd-8a39-ebd95cd26ee8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
