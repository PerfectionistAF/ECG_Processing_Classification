{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2103529a-7c1e-447a-9d4d-73276a09b450",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import wfdb\n",
    "import time\n",
    "import random\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "import sys\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "06ce5818-c9c8-4e0c-bd75-660c0b468a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install wfdb\n",
    "#!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "56f72e9d-2ad5-41b8-8712-0e9f3434da7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "##experiment with seed, run, channels(sinoatrial (SA) node, left feature lead, septal)\n",
    "##later experiment with channel averaging of physician diagnosis features of myocardial infarction\n",
    "##(septal average: v1, v2 ; left anterior average: v5, v6; left wrist: avl)\n",
    "seed_num = 39 #sys.argv[1]  ##required bash files\n",
    "#run_num = #sys.argv[2]\n",
    "channel_1 = 'v6'#sys.argv[3]\n",
    "channel_2 = 'vz'#sys.argv[4]\n",
    "channel_3 = 'ii'#sys.argv[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bd1acbe6-c2e0-4ba0-b8c8-c2e0365371bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./ptb-diagnostic-ecg-database-1.0.0/ptb-diagnostic-ecg-database-1.0.0/RECORDS') as fp:  \n",
    "    lines = fp.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2f4d607e-8cbd-44f9-8e17-e986a67b9f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##lines   ##read lines in dataset records.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f8138245-1855-4986-ae88-e4c4bea17ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "##divide into healthy and diseased .dat and .hea lists saved in files\n",
    "files_myocardial = []\n",
    "files_healthy = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "145971db-5e05-42ef-a887-dd9bf8d53f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in lines:\n",
    "    file_path = './ptb-diagnostic-ecg-database-1.0.0/ptb-diagnostic-ecg-database-1.0.0/' + file[:-1] + '.hea'\n",
    "    \n",
    "    ##read header to determine class ##focus on myocardial infarction\n",
    "    if 'Myocardial infarction' in open(file_path).read():\n",
    "        files_myocardial.append(file)\n",
    "        \n",
    "    if 'Healthy control' in open(file_path).read():\n",
    "        files_healthy.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6a62135b-911b-45d8-944c-68860212a0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#files_healthy  ##check with CONTROL\n",
    "#files_myocardial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d5671e03-660d-441e-ba4e-4380d2368557",
   "metadata": {},
   "outputs": [],
   "source": [
    "##shuffle data (cross-validation)\n",
    "np.random.seed(int(seed_num))\n",
    "np.random.shuffle(files_myocardial) \n",
    "np.random.shuffle(files_healthy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "48c8fd8d-5d58-4cc5-8419-022c1cd892e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "##split to train and test, 80% train, 20% test\n",
    "healthy_train = files_healthy[:int(0.8*len(files_healthy))]\n",
    "healthy_val = files_healthy[int(0.8*len(files_healthy)):]\n",
    "myocardial_train = files_myocardial[:int(0.8*len(files_myocardial))]\n",
    "myocardial_val = files_myocardial[int(0.8*len(files_myocardial)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "43d04e5d-7feb-4bf2-a735-6444010b3a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "##save names of train and val files\n",
    "h_train = pd.DataFrame(healthy_train)\n",
    "h_val = pd.DataFrame(healthy_val)\n",
    "m_train = pd.DataFrame(myocardial_train)\n",
    "m_val = pd.DataFrame(myocardial_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "102ea117-50a1-42af-942e-61fba09d6768",
   "metadata": {},
   "outputs": [],
   "source": [
    "h_train.to_csv(\"h_train_idx.csv\")\n",
    "m_train.to_csv(\"m_train_idx.csv\")\n",
    "h_val.to_csv(\"h_val_idx.csv\")\n",
    "m_val.to_csv(\"m_val_idx.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cc4f825a-703d-4959-8359-8b60181d4a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "##remove intersections\n",
    "def intersection(lst1, lst2): \n",
    "    return list(set(lst1) & set(lst2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d1c63aa6-e1ec-429b-827d-c1b9be79c033",
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_ids_healthy_train = []\n",
    "patient_ids_healthy_val = []\n",
    "patient_ids_myocardial_train = []\n",
    "patient_ids_myocardial_val = []\n",
    "##extract first 10 letters in file path string, which is the patient id\n",
    "for index in healthy_train:\n",
    "    patient_ids_healthy_train.append(index[0:10])\n",
    "for index in healthy_val:\n",
    "    patient_ids_healthy_val.append(index[0:10])\n",
    "for index in myocardial_train:\n",
    "    patient_ids_myocardial_train.append(index[0:10])\n",
    "for index in myocardial_val:\n",
    "    patient_ids_myocardial_val.append(index[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a82f70e7-4c45-4b0b-89d1-9bcd600253e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#type(patient_ids_myocardial_train)  ##list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "06dc89cf-0cd6-4d2d-82fc-62e217fdae55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(patient_ids_myocardial_train)) ##80% of total 148 patients is 118  \n",
    "#likely to have duplicates, so distribute intersection over train and validation sets\n",
    "#they can have common ecgs, used for checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "96c2dabd-4560-42ca-b140-a6a6fc1906cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(patient_ids_myocardial_val)) ##20% of total 148 patients is 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1a569adf-f848-4b29-a947-d4142c1d16ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#patient_ids_myocardial_val ##stable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "97c08128-a6d6-4d2b-96e7-3ba22cce0a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "intersection_myocardial = intersection(patient_ids_myocardial_train, patient_ids_myocardial_val)\n",
    "intersection_healthy = intersection(patient_ids_healthy_train, patient_ids_healthy_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "aaa14f6a-4a26-4a63-bcdb-85943db4bba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "##myocardial ##move half intersection to myocardial \n",
    "move_to_train = intersection_myocardial[:int(0.5*len(intersection_myocardial))]\n",
    "move_to_val = intersection_myocardial[int(0.5*len(intersection_myocardial)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "60ed47bd-beb4-4c7f-ac55-adaaf2e7b46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#move_to_train[0:5]  ##stable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b6ee2d21-7143-4279-8175-1308c5fd8a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for patient_id in move_to_train:\n",
    "    in_val = []\n",
    "    ##find and remove all files in val ecg readings by id\n",
    "    for file_ in myocardial_val:\n",
    "        if file_[:10] == patient_id:\n",
    "            in_val.append(file_)\n",
    "            myocardial_val.remove(file_)\n",
    "            \n",
    "    ##add to train\n",
    "    for file_ in in_val:\n",
    "        myocardial_train.append(file_)\n",
    "\n",
    "for patient_id in move_to_val:    \n",
    "    in_train = []\n",
    "    ##find and remove all files in train\n",
    "    for file_ in myocardial_train:\n",
    "        if file_[:10] == patient_id:\n",
    "            in_train.append(file_)\n",
    "            myocardial_train.remove(file_)\n",
    "            \n",
    "    ##add to val\n",
    "    for file_ in in_train:\n",
    "        myocardial_val.append(file_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b1a0b4a1-4b07-47de-a74f-de8ef4d1a38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##healthy\n",
    "move_to_train = intersection_healthy[:int(0.5*len(intersection_healthy))]\n",
    "move_to_val = intersection_healthy[int(0.5*len(intersection_healthy)):]\n",
    "#print(move_to_train[0:5]) ##stable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0f244c4a-5a55-4614-8b95-df4c111ea7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for patient_id in move_to_train:\n",
    "    in_val = []\n",
    "    ##find and remove all files in val ecg readings by id\n",
    "    for file_ in healthy_val:\n",
    "        if file_[:10] == patient_id:\n",
    "            in_val.append(file_)\n",
    "            healthy_val.remove(file_)\n",
    "            \n",
    "    ##add to train\n",
    "    for file_ in in_val:\n",
    "        healthy_train.append(file_)\n",
    "\n",
    "for patient_id in move_to_val:    \n",
    "    in_train = []\n",
    "    ##find and remove all files in train\n",
    "    for file_ in healthy_train:\n",
    "        if file_[:10] == patient_id:\n",
    "            in_train.append(file_)\n",
    "            healthy_train.remove(file_)\n",
    "            \n",
    "    ##add to val\n",
    "    for file_ in in_train:\n",
    "        healthy_val.append(file_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4984aba2-bfc2-4cab-8701-2a44efbc9707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(myocardial_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "137a9d3d-1fa7-4084-9de7-3e38db1cd1eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'patient240/s0468_re'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "healthy_train[0][:-1]  ##example file directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "be6d2e99-74d5-4147-8002-d6194b3261d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "##update index files\n",
    "h_train = pd.DataFrame(healthy_train)\n",
    "h_val = pd.DataFrame(healthy_val)\n",
    "m_train = pd.DataFrame(myocardial_train)\n",
    "m_val = pd.DataFrame(myocardial_val)\n",
    "h_train.to_csv(\"h_train_idx.csv\")\n",
    "m_train.to_csv(\"m_train_idx.csv\")\n",
    "h_val.to_csv(\"h_val_idx.csv\")\n",
    "m_val.to_csv(\"m_val_idx.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e337e579-ba75-44b8-851a-ca6b7ffbe674",
   "metadata": {},
   "outputs": [],
   "source": [
    "##all files extracted and cleaned successfully\n",
    "##now prepare a dataframe for the 3 channels\n",
    "##Index----II----V6----VZ\n",
    "data_healthy_train = []\n",
    "for file in healthy_train:\n",
    "    ##records for each\n",
    "    data_ii, _ = wfdb.rdsamp('./ptb-diagnostic-ecg-database-1.0.0/ptb-diagnostic-ecg-database-1.0.0/' + file[:-1], channel_names=[str(channel_1)])\n",
    "    data_v6, _ = wfdb.rdsamp('./ptb-diagnostic-ecg-database-1.0.0/ptb-diagnostic-ecg-database-1.0.0/' + file[:-1], channel_names=[str(channel_2)])\n",
    "    data_vz, _ = wfdb.rdsamp('./ptb-diagnostic-ecg-database-1.0.0/ptb-diagnostic-ecg-database-1.0.0/' + file[:-1], channel_names=[str(channel_3)])\n",
    "    data = [data_ii.flatten(), data_v6.flatten(), data_vz.flatten()]  ##flatten to input directly into keras model\n",
    "    data_healthy_train.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "171c970b-b99f-4780-8db0-0648ac5f3347",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-0.1245, -0.1275, -0.1305, ...,  0.188 ,  0.187 ,  0.1855]),\n",
       " array([ 0.458 ,  0.458 ,  0.457 , ..., -0.335 , -0.3325, -0.329 ]),\n",
       " array([-0.1025, -0.1   , -0.0925, ...,  0.062 ,  0.0695,  0.065 ])]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_healthy_train[0][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b231c499-66ed-4211-9a41-604b4dd7cbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "healthy_train_set = pd.DataFrame(data_healthy_train, columns=['ii', 'v6', 'vz'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f4b0d7f4-1b57-4761-87f4-4dfb65042591",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.1245, -0.1275, -0.1305, ...,  0.188 ,  0.187 ,  0.1855])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "healthy_train_set.at[0, 'ii'] ##input the first healthy patient in training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "cd724c82-87e8-4d54-b72d-f063e99ff60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "healthy_train_set.to_csv(\"healthy_train_signals.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7834d696-4abd-417f-b418-57d7c6fda2f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=60, step=1)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "healthy_train_set.index  ##test for iterating over rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4cd702eb-06a3-4831-95d9-37b901a01761",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_healthy_val = []\n",
    "for file in healthy_val:\n",
    "    ##records for each\n",
    "    data_ii, _ = wfdb.rdsamp('./ptb-diagnostic-ecg-database-1.0.0/ptb-diagnostic-ecg-database-1.0.0/' + file[:-1], channel_names=[str(channel_1)])\n",
    "    data_v6, _ = wfdb.rdsamp('./ptb-diagnostic-ecg-database-1.0.0/ptb-diagnostic-ecg-database-1.0.0/' + file[:-1], channel_names=[str(channel_2)])\n",
    "    data_vz, _ = wfdb.rdsamp('./ptb-diagnostic-ecg-database-1.0.0/ptb-diagnostic-ecg-database-1.0.0/' + file[:-1], channel_names=[str(channel_3)])\n",
    "    data = [data_ii.flatten(), data_v6.flatten(), data_vz.flatten()]  ##flatten to input directly into keras model\n",
    "    data_healthy_val.append(data)\n",
    "\n",
    "healthy_val_set = pd.DataFrame(data_healthy_train, columns=['ii', 'v6', 'vz'] )\n",
    "healthy_val_set.to_csv(\"healthy_val_signals.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "de0be2a4-a9dd-4189-86bc-e01a8f357c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_unhealthy_train = []\n",
    "for file in myocardial_train:\n",
    "    ##records for each\n",
    "    data_ii, _ = wfdb.rdsamp('./ptb-diagnostic-ecg-database-1.0.0/ptb-diagnostic-ecg-database-1.0.0/' + file[:-1], channel_names=[str(channel_1)])\n",
    "    data_v6, _ = wfdb.rdsamp('./ptb-diagnostic-ecg-database-1.0.0/ptb-diagnostic-ecg-database-1.0.0/' + file[:-1], channel_names=[str(channel_2)])\n",
    "    data_vz, _ = wfdb.rdsamp('./ptb-diagnostic-ecg-database-1.0.0/ptb-diagnostic-ecg-database-1.0.0/' + file[:-1], channel_names=[str(channel_3)])\n",
    "    data = [data_ii.flatten(), data_v6.flatten(), data_vz.flatten()]  ##flatten to input directly into keras model\n",
    "    data_unhealthy_train.append(data)\n",
    "\n",
    "data_unhealthy_val = []\n",
    "for file in myocardial_val:\n",
    "    ##records for each\n",
    "    data_ii, _ = wfdb.rdsamp('./ptb-diagnostic-ecg-database-1.0.0/ptb-diagnostic-ecg-database-1.0.0/' + file[:-1], channel_names=[str(channel_1)])\n",
    "    data_v6, _ = wfdb.rdsamp('./ptb-diagnostic-ecg-database-1.0.0/ptb-diagnostic-ecg-database-1.0.0/' + file[:-1], channel_names=[str(channel_2)])\n",
    "    data_vz, _ = wfdb.rdsamp('./ptb-diagnostic-ecg-database-1.0.0/ptb-diagnostic-ecg-database-1.0.0/' + file[:-1], channel_names=[str(channel_3)])\n",
    "    data = [data_ii.flatten(), data_v6.flatten(), data_vz.flatten()]  ##flatten to input directly into keras model\n",
    "    data_unhealthy_val.append(data)\n",
    "\n",
    "unhealthy_train_set = pd.DataFrame(data_unhealthy_train, columns=['ii', 'v6', 'vz'] )\n",
    "unhealthy_train_set.to_csv(\"mi_train_signals.csv\")\n",
    "unhealthy_val_set = pd.DataFrame(data_unhealthy_val, columns=['ii', 'v6', 'vz'] )\n",
    "unhealthy_val_set.to_csv(\"mi_val_signals.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f4a347bc-2ee8-418a-a78e-677783d19564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[73, 69, 55, 260, 177]\n",
      "[-0.445  -0.445  -0.443  ...  0.0925  0.096   0.097 ]\n",
      "[-0.201  -0.1885 -0.1905 ... -0.1065 -0.108  -0.1095]\n",
      "[-1.29   -1.2855 -1.2905 ...  0.3335  0.341   0.336 ]\n"
     ]
    }
   ],
   "source": [
    "##########DEBUGGING: TEST GENERATION OF SLICES\n",
    "#unhealthy_indices = random.sample(sorted(np.arange(len(data_unhealthy_train))), k= 5)\n",
    "#print(unhealthy_indices)\n",
    "#unhealthy_batch = []\n",
    "#for i in unhealthy_indices:\n",
    "#    unhealthy_batch.append(data_unhealthy_train[i])\n",
    "\n",
    "#print(unhealthy_batch[0][0])\n",
    "#print(unhealthy_batch[0][1])\n",
    "#print(unhealthy_batch[0][2])\n",
    "##########DEBUGGING: TEST GENERATION OF SLICES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "489e7da8-8c39-4a03-acd8-4253e9480e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############COMPONENT ONE IN .PY FILES##############\n",
    "##normalize into batches, batch x and batch y (independent and dependent)\n",
    "##minmax norm\n",
    "window_size = 10000  ##from each ecg reading\n",
    "def get_batch(batch_size, split='train'):\n",
    "    ##random sampling of batches\n",
    "    ##divide batch number in half to improve speed of network\n",
    "    if split == 'train':\n",
    "        ##random samples from sorted per batch with size k = batch_size / 2\n",
    "        ##mimic shuffling\n",
    "        unhealthy_indices = random.sample(sorted(np.arange(len(data_unhealthy_train))), k=int(batch_size / 2))\n",
    "        healthy_indices = random.sample(sorted(np.arange(len(data_healthy_train))), k=int(batch_size / 2))\n",
    "        unhealthy_batch = []\n",
    "        healthy_batch = []\n",
    "        for i in unhealthy_indices:\n",
    "            unhealthy_batch.append(data_unhealthy_train[i])\n",
    "        for j in healthy_indices:\n",
    "            healthy_batch.append(data_healthy_train[j])\n",
    "    elif split == 'val': \n",
    "        unhealthy_indices = random.sample(sorted(np.arange(len(data_unhealthy_val))), k=int(batch_size / 2))\n",
    "        healthy_indices = random.sample(sorted(np.arange(len(data_healthy_val))), k=int(batch_size / 2))\n",
    "        unhealthy_batch = []\n",
    "        healthy_batch = []\n",
    "        for i in unhealthy_indices:\n",
    "            unhealthy_batch.append(data_unhealthy_val[i])\n",
    "        for j in healthy_indices:\n",
    "            healthy_batch.append(data_healthy_val[j])\n",
    "\n",
    "    \n",
    "    batch_x = []  ##batch of mixed healthy and unhealthy data\n",
    "    for sample in unhealthy_batch: ##if val or if train\n",
    "        start = random.choice(np.arange(len(sample[0]) - window_size))  ##randomly sample window from ecg \n",
    "        # normalize ecg values \n",
    "        normalized_1 = minmax_scale(sample[0][start:start+window_size])\n",
    "        normalized_2 = minmax_scale(sample[1][start:start+window_size])\n",
    "        normalized_3 = minmax_scale(sample[2][start:start+window_size])\n",
    "        normalized = np.array((normalized_1, normalized_2, normalized_3))\n",
    "        batch_x.append(normalized)\n",
    "        \n",
    "    for sample in healthy_batch:\n",
    "        start = random.choice(np.arange(len(sample[0]) - window_size))\n",
    "        # normalize\n",
    "        normalized_1 = minmax_scale(sample[0][start:start+window_size])\n",
    "        normalized_2 = minmax_scale(sample[1][start:start+window_size])\n",
    "        normalized_3 = minmax_scale(sample[2][start:start+window_size])\n",
    "        normalized = np.array((normalized_1, normalized_2, normalized_3))\n",
    "        batch_x.append(normalized)\n",
    "    \n",
    "    batch_y = [0.1 for _ in range(int(batch_size / 2))]\n",
    "    for _ in range(int(batch_size / 2)):\n",
    "        batch_y.append(0.9)\n",
    "        \n",
    "    indices = np.arange(len(batch_y))\n",
    "    np.random.shuffle(indices)\n",
    "    \n",
    "    batch_x = np.array(batch_x)\n",
    "    batch_y = np.array(batch_y)\n",
    "    \n",
    "    batch_x = batch_x[indices]\n",
    "    batch_y = batch_y[indices]\n",
    "    \n",
    "    batch_x = np.reshape(batch_x, (-1, 3, window_size))\n",
    "    batch_x = torch.from_numpy(batch_x)\n",
    "    batch_x = batch_x.float()#.cuda()\n",
    "    batch_x = batch_x.float()\n",
    "    \n",
    "    batch_y = np.reshape(batch_y, (-1, 1))\n",
    "    batch_y = torch.from_numpy(batch_y)  ##save tensors\n",
    "    batch_y = batch_y.float()#.cuda()\n",
    "    batch_y = batch_y.float()\n",
    "    \n",
    "    return batch_x, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "a62c26e3-8a2f-4acd-8f41-656e9bf866e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "##constant batch size = 16  ##due to images ##or can be 10 \n",
    "##test given train\n",
    "##batch_x is the normalized windows of ecg channels in both healthy and unhealthy\n",
    "batch_size = 10\n",
    "#batch_x, batch_y = get_batch(batch_size, split='train') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b4be6fb1-9adb-47b0-b1d1-41a03852650f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##save batch tensors in .txt for ready training and testing\n",
    "##assume 80 training batches and 20 testing batches ##each batch has a size of 5 or 8\n",
    "torch.save(batch_x, 'batch_x.pt')  ##encode in utf_8\n",
    "torch.save(batch_y, 'batch_y.pt')  ##encode in utf_8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "2ab8f00b-1d8b-4e69-a16f-de4a681af03b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.2105, 0.2093, 0.2101,  ..., 0.1412, 0.1399, 0.1452],\n",
       "         [0.5839, 0.5845, 0.5839,  ..., 0.5336, 0.5342, 0.5336],\n",
       "         [0.3101, 0.3105, 0.3116,  ..., 0.1840, 0.1840, 0.1867]],\n",
       "\n",
       "        [[0.2089, 0.2042, 0.2042,  ..., 0.0450, 0.0454, 0.0399],\n",
       "         [0.3956, 0.3941, 0.3926,  ..., 0.3554, 0.3521, 0.3475],\n",
       "         [0.4373, 0.4537, 0.4638,  ..., 0.2777, 0.2671, 0.2715]],\n",
       "\n",
       "        [[0.2367, 0.2376, 0.2363,  ..., 0.2185, 0.2168, 0.2222],\n",
       "         [0.2886, 0.2895, 0.2886,  ..., 0.3931, 0.3941, 0.3945],\n",
       "         [0.4784, 0.4683, 0.4656,  ..., 0.3410, 0.3282, 0.3322]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.4326, 0.4326, 0.4351,  ..., 0.0783, 0.0802, 0.0727],\n",
       "         [0.5226, 0.5202, 0.5240,  ..., 0.5753, 0.5672, 0.5515],\n",
       "         [0.0419, 0.0443, 0.0445,  ..., 0.8134, 0.8141, 0.8136]],\n",
       "\n",
       "        [[0.0107, 0.0093, 0.0073,  ..., 0.0794, 0.0788, 0.0774],\n",
       "         [0.4003, 0.3981, 0.3981,  ..., 0.4753, 0.4727, 0.4710],\n",
       "         [0.4146, 0.4155, 0.4155,  ..., 0.5292, 0.5288, 0.5281]],\n",
       "\n",
       "        [[0.7523, 0.6884, 0.6269,  ..., 0.2159, 0.2187, 0.2196],\n",
       "         [0.7516, 0.7597, 0.7703,  ..., 0.1783, 0.1791, 0.1742],\n",
       "         [0.3876, 0.3638, 0.3346,  ..., 0.6444, 0.6417, 0.6423]]])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##in model, import the get_batches from this module then start\n",
    "torch.load('batch_x.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a23e6783-3ad3-4e1b-8771-98f6fa7d1fc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9000],\n",
       "        [0.9000],\n",
       "        [0.1000],\n",
       "        [0.9000],\n",
       "        [0.1000],\n",
       "        [0.9000],\n",
       "        [0.1000],\n",
       "        [0.1000],\n",
       "        [0.1000],\n",
       "        [0.9000]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.load('batch_y.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185efb9d-1ad1-4d7b-9ae7-ac47fc9503c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
